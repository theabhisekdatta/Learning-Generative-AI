{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langchain, openai key and HUggingFace API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from constant import openai_key\n",
    "from huggingface_Api import HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the openai env key globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Langchain Initialize the OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.8) # More the value towards 1 more random the LLM would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \" what is the capital of india\"\n",
    "print(llm.predict(text)) # also we can use (llm.invoke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Huggingface \n",
    "##### We can use opensource model from Huggingface\n",
    "##### Declare the env globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use \"google/flan-t5-large\" it is a opensource model from Huggingface, also we are testing it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\")#,model_kwargs={\"temperature\":0,\"max_lenght\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average temperature in New Delhi is 1Â°C, while in Kolkata it is \n"
     ]
    }
   ],
   "source": [
    "text_hug=\"what is the weather in new delhi and kolkata\"\n",
    "print(llm_huggingface.predict(text_hug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare it with OpenAI LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, I do not have real-time weather information. You can check the weather in New Delhi and Kolkata by using a reliable weather website or app.\n"
     ]
    }
   ],
   "source": [
    "text_openai_llm=\"what is the weather in new delhi and kolkata\"\n",
    "print(llm.predict(text_openai_llm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me something about the country India'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=[\"country\"],\n",
    "               template=\"Tell me something about the country {country}\")\n",
    "\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India is the seventh-largest country in the world by land area and the second-most populous country, with over 1.3 billion people. It is located in South Asia and is known for its rich cultural heritage, diverse languages, and vibrant traditions. India is a federal parliamentary democratic republic with a President as its head of state and a Prime Minister as its head of government. The country is also known for its Bollywood film industry, spicy cuisine, and ancient history dating back thousands of years. India is a major player in the global economy and is known for its IT industry, agriculture, and textile manufacturing.\n"
     ]
    }
   ],
   "source": [
    "## To run the prompt and the llm along with it we need llm chain.\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain (llm=llm, prompt=prompt_template) ## Open AI LLM\n",
    "\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Multiple Chain using simple Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating 2 chains\n",
    "capital_prompt = PromptTemplate(input_variables = [\"country\"],\n",
    "                              template = \"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_prompt)\n",
    "\n",
    "famous_prompt = PromptTemplate(input_variables = [\"capital\"],\n",
    "                               template=\"Please tell me the famous places in {capital}\")\n",
    "\n",
    "famous_chain  = LLMChain(llm = llm, prompt = famous_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some famous places in New Delhi, the capital of India, include:\n",
      "\n",
      "1. Red Fort\n",
      "2. India Gate\n",
      "3. Qutub Minar\n",
      "4. Lotus Temple\n",
      "5. Humayun's Tomb\n",
      "6. Jama Masjid\n",
      "7. Akshardham Temple\n",
      "8. Rashtrapati Bhavan (President's House)\n",
      "9. Chandni Chowk\n",
      "10. National Museum\n",
      "\n",
      "These are just a few of the many iconic landmarks and destinations in New Delhi that attract tourists from around the world.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "simple_seq_chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "print(simple_seq_chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating 2 chains\n",
    "capital_prompt = PromptTemplate(input_variables = [\"country\"],\n",
    "                              template = \"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain = LLMChain(llm = llm, prompt = capital_prompt, output_key = \"capital\")\n",
    "\n",
    "famous_prompt = PromptTemplate(input_variables = [\"capital\"],\n",
    "                               template=\"Please tell me the famous places in {capital}\")\n",
    "\n",
    "famous_chain  = LLMChain(llm = llm, prompt = famous_prompt, output_key = \"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'India', 'text': 'India is the seventh-largest country in the world by land area and the second-most populous country, with over 1.3 billion people. It is located in South Asia and is known for its rich history, diverse culture, and vibrant traditions. India is also home to a wide variety of languages, religions, and cuisines, making it a truly unique and dynamic country. Additionally, India is known for its contributions to the fields of science, technology, and art, and has a rapidly growing economy that has made it one of the fastest-growing major economies in the world.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "seq_chain = SequentialChain(chains = [capital_chain, famous_chain],\n",
    "                            input_variables=[\"country\"], output_variables= [\"capital\", \"places\"])\n",
    "\n",
    "print(chain({\"country\":\"India\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chatmodels (LangChain) with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "# so when we use chatmodels we use 3 schemas\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "# Reinitialing ChatLLM model from OpenAI\n",
    "chat_llm = ChatOpenAI(temperature=0.6,model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure, here are some AI jokes for you:\\n\\n1. Why did the robot go to school? Because it wanted a little byte of knowledge!\\n2. How does a computer say goodbye? \"Byte, byte, byte!\"\\n3. Why was the computer cold? It left its Windows open!\\n4. Why did the robot break up with his girlfriend? She couldn\\'t handle his motherboard issues!\\n5. How do robots send messages? By Bluetooth!\\n\\nI hope these jokes bring a smile to your face!')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let use the 3 schemas HumanMessage(Human Input), SystemMessage(Instruction to the chatbot),AIMessage (Output of the chatbot)  \n",
    "chat_llm([\n",
    "    SystemMessage(content=\"You are a Comedian AI assitant\"), # this is what I tell my chatbot to behave like\n",
    "    HumanMessage(content=\"Let me some jokes of AI\") # Input from Human\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt template + LLM + Output Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser ## I want to modify any output of an LLM before hand we use Output parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Chat prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpfull assistant. Whenever a user gives input, you should generate 5 words synonyms in comma seperated\"\n",
    "human_template = \"{text}\"\n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To run this chatprompt we need chain \n",
    "## Here chatprompt is the prompt along with system and human message\n",
    "## chatllm is the chat llm from openai\n",
    "## commaseperatedoutput is the class from the Output parser\n",
    "output_parser_chain = chatprompt | chat_llm | Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Intelligent', ' clever', ' smart', ' brainy', ' astute']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser_chain.invoke({\"text\": \"Interligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
